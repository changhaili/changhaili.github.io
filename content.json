{"meta":{"title":"乱石海","subtitle":"李昌海的个人博客--在这里写下我的技术杂念","description":"李昌海的个人博客--在这里写下我的技术杂念","author":"李昌海","url":"http://www.lichanghai.com"},"pages":[{"title":"关于","date":"2018-11-17T12:35:58.000Z","updated":"2018-11-23T17:39:41.490Z","comments":true,"path":"about/index.html","permalink":"http://www.lichanghai.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Flink实时计算数据落盘方案","slug":"flink-timer-queue","date":"2018-11-30T11:33:36.000Z","updated":"2018-12-02T01:35:27.275Z","comments":true,"path":"2018/11/30/flink-timer-queue/","link":"","permalink":"http://www.lichanghai.com/2018/11/30/flink-timer-queue/","excerpt":"","text":"Flink实时计算数据落盘方案背景我们使用Flink进行实时统计，并将计算结果更新到Sink中进而实现数据落盘，为了描述方便，我们以落盘到MySQL为例。考虑到MySQL读写性能，我们使用双缓存加定时批量Flush的方式更新数据库。在实施过程中碰到了一些问题： Flush时会对数据库的产生极大的压力。 背压，由于使用双缓存，Flink计算的结果只写入内存，无法产生Flush到MySQL时的压力。 数据的完整性，由于在Flush之前，Flink计算的结果还在内存中，当宕机或Task退出都会造成数据丢失。 下面将讨论我们是如何解决上述问题的。 数据去重使用Map进行数据去重，减少MySQL压力。 考虑到Flink计算的大多数操作是统计，如Sum, Count，Max等，在实时流中，每来一条数据都是对结果进行更新，即后来的计算结果会覆盖原来的结果，所以没有必须要每次的计算结果都写到数据库。 我们在内存中进行去重。即使用一个Map缓存，期中Key为聚合的维度，Value是每次计算的结果。每次Flink的计算都put到该Map。后期定时将该缓存Flush到MySQL中。 考虑到维度的基数远小于实时流中消息的数量，将极大缓解数据Flush到MySQL的压力。当然还可以按Task进行分库分表，进一步分摊单个数据库的压力。 定时队列我们使用定时任务将内存中的数据Flush到MySQL中。为此我们定义了一个定时队列。 主要包括两个数据结构： push buffer：内部是一个HashMap，用于缓存去重的结果。 pull buffer：一个链表，当时需要Flush的数据 主要实现了三个方法： Swap: 交换缓存，即将push buffer中的数据交换到pull buffer中，该函数为定时调用。 push: Flink调用该方法将数据push到队列中，如果在一个swap周期内pull buffer中还有数据没有flush到mysql，该方法将阻塞。 pull：Flush线程从pull buffer的头部获取数据 并将该数据写到MySQL中，如果pull buffer为空，该方法阻塞。 主要流程： Flink会一直push数据到定时队列中，如果存在背压，则push方法阻塞，直到pull buffer中的数据为空。 swap时会将当前push buffer中的数据复制到pull buffer中，则清空push buffer，这样push buffer中只会存在一个swap周期内更新过的数据，而这段时间的数据量一般会远小于聚合维度的基数。如果swap时pull buffer还存在数据，可以选择阻塞等待或放弃这些周期。除非特别情况（如：checkpoint），否则可以放弃本次周期，这样并不影响最终结果的正确性。 Flush线程或外部任务调用pull方法将拉取数据（一次可以拉取多条，甚至所有的数据），并将拉取后的数据写到MySQL中。如果pull buffer中没有数据，则pull方法阻塞，直到swap方法被调用。 结合Checkpoint定时队列结合Checkpoint，用于实现数据的完整性。 Checkpoint是Flink用于保证完整性的机制，我们需要在Checkpoint中时将定时队列中的数据所有数据都写到MySQL中。流程如下：首先调用时间队列的swap，将push buffer中的数据都交换到pull buffer上，再将pull方法从pull buffer中的获取数据进而写到MySQL中。 讨论以下分两种情况： Checkpoint时调用Swap方法，同时pull buffer中没有数据，调用swap可以直接返回，再将pull buffer中的数据写到数据库中 Checkpoint时调用Swap方法，同时pull buffer中存在数据，则调用swap时需要让swap阻塞，即而阻塞Checkpoint，直到其他任务先将pull buffer都写到数据，Swap返回继续执行Checkpoint操作。 Swap方法保证了线程安全，Checkpoint线程与其他线程无法同时进入该方法。 综上所述，我们只要保证在调用swap方法时，如有背压能阻塞，就能保存数据的完整性。 源代码PushBuffer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface PushBuffer&lt;T&gt; &#123; void add(T obj); void clear(); T get(Object tag); Iterable&lt;T&gt; values(); int size();&#125;public class TimerQueueMapBuffer&lt;T&gt; implements PushBuffer&lt;T&gt; &#123; private final Map&lt;Object, T&gt; map = Maps.newConcurrentMap(); private final Function&lt;T, Object&gt; keyGetter; public TimerQueueMapBuffer(Function&lt;T, Object&gt; keyGetter)&#123; this.keyGetter = keyGetter; &#125; @Override public void add(T obj) &#123; Object key = keyGetter.apply(obj); map.put(key, obj); &#125; @Override public void clear() &#123; map.clear(); &#125; @Override public T get(Object tag) &#123; return map.get(tag); &#125; @Override public int size() &#123; return map.size(); &#125; @Override public Iterable&lt;T&gt; values() &#123; return map.values(); &#125;&#125; TimerQueue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220public class TimerQueue&lt;T&gt; &#123; public final static long WAIT_TIME_MS = 100; public final static int PULL_FULL_SIZE = -1; public static Logger logger = LoggerFactory.getLogger(TimerQueue.class); private final Supplier&lt;PushBuffer&lt;T&gt;&gt; bufferSupplier; private final long expiredTime; public TimerQueue(Supplier&lt;PushBuffer&lt;T&gt;&gt; bufferSupplier, long expiredTime, boolean autoSwap, Consumer&lt;List&lt;T&gt;&gt; consumer) &#123; this.bufferSupplier = bufferSupplier; this.expiredTime = expiredTime; if (autoSwap) &#123; Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; &#123; try &#123; this.swap(true); &#125; catch (Exception ex) &#123; logger.error(\"failed to swap buffer\", ex); &#125; &#125;, 0, expiredTime, TimeUnit.MICROSECONDS); &#125; if (consumer != null) &#123; Executors.newSingleThreadExecutor().submit(() -&gt; this.pub(consumer)); &#125; &#125; public TimerQueue(Supplier&lt;PushBuffer&lt;T&gt;&gt; bufferSupplier, long expiredTime) &#123; this(bufferSupplier, expiredTime, true, null); &#125; private volatile long swapTime = -1; private volatile PushBuffer&lt;T&gt; pushBuffer; private volatile LinkedList&lt;T&gt; pullBuffer = new LinkedList&lt;&gt;(); private volatile boolean swapping = false; private final Lock lock = new ReentrantLock(); private final Condition pushCondition = lock.newCondition(); private final Condition pullCondition = lock.newCondition(); protected boolean hasPressure() &#123; boolean pressure = System.currentTimeMillis() - swapTime &gt; expiredTime; if (pressure) &#123; pressure = getPullSize() &gt; 0; &#125; return pressure; &#125; public void push(T obj) &#123; if (pushBuffer == null) &#123; try &#123; lock.lock(); if (pushBuffer == null) &#123; pushBuffer = bufferSupplier.get(); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; try &#123; lock.lock(); while (swapping || hasPressure()) &#123; try &#123; pushCondition.await(WAIT_TIME_MS, TimeUnit.MICROSECONDS); &#125; catch (Exception ex) &#123; logger.error(\"await push condition error\", ex); &#125; &#125; pushBuffer.add(obj); &#125; finally &#123; lock.unlock(); &#125; &#125; public boolean swap(boolean retryIfFailed) &#123; if (retryIfFailed) &#123; while (true) &#123; try &#123; if (swap()) return true; Thread.sleep(WAIT_TIME_MS); &#125; catch (Exception ex) &#123; logger.error(\"failed to swap buffer\", ex); &#125; &#125; &#125; else &#123; return swap(); &#125; &#125; public boolean swap() &#123; try &#123; lock.lock(); if (swapping || getPullSize() &gt; 0) &#123; return false; &#125; swapping = true; pullBuffer = new LinkedList&lt;&gt;(); if (pushBuffer != null) &#123; for (T v : pushBuffer.values()) &#123; pullBuffer.add(v); &#125; &#125; this.pushBuffer = bufferSupplier.get(); this.swapTime = System.currentTimeMillis(); pullCondition.signalAll(); return true; &#125; finally &#123; swapping = false; lock.unlock(); &#125; &#125; private void pub(Consumer&lt;List&lt;T&gt;&gt; consumer) &#123; if (consumer == null) return; while (true) &#123; try &#123; List&lt;T&gt; list = this.pull(PULL_FULL_SIZE, WAIT_TIME_MS); if (list == null) &#123; continue; &#125; consumer.accept(list); &#125; catch (Exception ex) &#123; logger.error(\"failed to callback listener\", ex); &#125; &#125; &#125; public int getPushSize() &#123; PushBuffer&lt;T&gt; pushBuffer = this.pushBuffer; return pushBuffer == null ? 0 : pushBuffer.size(); &#125; public int getPullSize() &#123; LinkedList&lt;T&gt; pullBuffer = this.pullBuffer; return pullBuffer == null ? 0 : pullBuffer.size(); &#125; public List&lt;T&gt; pull(int size, long waitTimeMs) &#123; try &#123; lock.lock(); long waitTime = waitTimeMs == -1 ? WAIT_TIME_MS : waitTimeMs; while (getPullSize() == 0) &#123; try &#123; pullCondition.await(waitTime, TimeUnit.MICROSECONDS); if (waitTimeMs != -1l) break; &#125; catch (Exception ex) &#123; logger.info(\"exception\", ex); &#125; &#125; boolean pressure = hasPressure(); List&lt;T&gt; list; if (size == -1) &#123; list = pullBuffer; pullBuffer = null; &#125; else &#123; list = new ArrayList&lt;&gt;(); for (int i = 0, pullSize = getPullSize(); i &lt; size &amp;&amp; i &lt; pullSize; i++) &#123; list.add(pullBuffer.pollFirst()); &#125; &#125; if (pressure &amp;&amp; getPullSize() == 0) &#123; pushCondition.signalAll(); &#125; return list; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 问题 在同一个线程中swap后立即pull，可能会造成死锁 需要在pull中使用超时参数让阻塞时也能返回。其中 -1，表示一直阻塞。如在checkpoint中，调用如下： timerQueue.swap(true); timerQueue.pull(oncePullSize, timeWaitMs) ; // 如 timerQueue.pull( 10, 200); 不要一次获取所有数据 获取所有数据会造成pull buffer数据为空，而将buffer放在本地缓存特后续处理，这样Flink会以为所有的数据都已处理完成，造成无背压的假象，在进行Checkpoint时因无法获取到所有数据而造成数据不完全，同时也会对MySQL造成压力。 目前极端情况下会造成pull出一批（一条）数据但没有及时写入MySQL中。建议保证数据落盘相关代码线程安全。后期考虑添加数据确认机制，即保存数据落盘完成后才真正从pull buffer中删除数据。","categories":[],"tags":[{"name":"flink","slug":"flink","permalink":"http://www.lichanghai.com/tags/flink/"},{"name":"多线程","slug":"多线程","permalink":"http://www.lichanghai.com/tags/多线程/"},{"name":"背压","slug":"背压","permalink":"http://www.lichanghai.com/tags/背压/"},{"name":"双缓存","slug":"双缓存","permalink":"http://www.lichanghai.com/tags/双缓存/"}],"keywords":[]},{"title":"博客迁移","slug":"blog-migrate-1","date":"2018-11-17T16:02:20.000Z","updated":"2018-11-26T07:31:39.499Z","comments":true,"path":"2018/11/18/blog-migrate-1/","link":"","permalink":"http://www.lichanghai.com/2018/11/18/blog-migrate-1/","excerpt":"","text":"博客曾经在AWS上运行过一段时间，云主机到期后没就再处理。现迁移到阿里云上重新运行。","categories":[],"tags":[],"keywords":[]},{"title":"不规则图形的轮廓识别及其周长计算","slug":"edge-len","date":"2018-02-04T15:41:12.000Z","updated":"2018-12-02T09:09:46.546Z","comments":true,"path":"2018/02/04/edge-len/","link":"","permalink":"http://www.lichanghai.com/2018/02/04/edge-len/","excerpt":"","text":"不规则图形的轮廓识别及其周长计算源码：https://github.com/changhaili/edgelen 1 简介edgelen是一个对图片中不规则图形的轮廓进行识别并计算其周长的java程序，纯Java实现。用到的算法有： ​ Kmeans ​ 混合高斯模型 ​ 层次聚类 ​ 密度聚类 ​ 线程回归 ​ 高斯滤波，拉普拉斯滤波 ​ B样条插值 其中： ​ Kmeans和GMM都用于识别前景色和背景色 ​ 层次聚类和密码都用于形状识别 ​ 滤波用于平滑及获取物体边缘 ​ B样条插值用于计算长度 该库可以在任何支持Java的程序中使用。比如可以封装在Android APP中。 分别在输入框中输入背景的长与宽，选择背景的颜色，待测物的颜色，点确定，进入如下页面 选择拍照，拍照确定后，会显示相应的长度。 edgelen是根据待测物在参考背景中的位置关系以及参考背景的尺寸（长宽），计算出待测物的周长。 2 实现思路2.1 整体思路下面讲述实现思路时，将以该图片为例子进行描述。 原始图像查看：https://github.com/changhaili/edgelen/blob/master/images/naive.JPG 参考为红底白纸，即背景为一张红纸，本示例需要识别出三张白纸的周长。 识别背景色及前景色 去除图片的上下左右边缘，随机采样出部分像素点 使用聚类根据像素点颜色值 将颜色聚成两类 计算两个类簇内部像素点的平均距离，平均距离为大者所对应的颜色为背景色（本例为红色），小者为前色（本例为白色） 背景处理及坐标生成 使用颜色聚类的结果读取所有背景色（红色）的像素点 对红包像素点进行聚类，将 聚类后的簇 按包含的像素点数量倒序，只第一个簇为背景 将背景顺时针旋转45度 取出最外侧像素点，并分成四组，最原始背景的左侧边，上侧边，右侧边，下侧边 将各边回归出一条直接，分别得到四条直线 求四条直接的交点，即可以获取 上下左右 四个控制点 将四个控制点逆时针旋转45度 根据四个控制 点生成投影坐标 待测图形的边缘设别及曲线生成 将待测图形进行聚类 根据输入的待测图形的数量返回聚类后的 簇 将 聚类后的像素点进行 Laplace平滑，并获取边缘像素点 使用方位角游走的方式，将边缘像素点生成多线数（曲线） 曲线长度计算 曲线上的像素点进行 滤波，可以使用高斯滤波或平均滤波 对像素点进行多次采样 对像素点使用B样条插值 微分B曲线并计算 欧式距离 加权平均多次采样结果，即为周长 如上例中，红纸的长宽为：1052 * 730； 单位为毫米，手工软布尺测量，稍有误差。 最后识别出三张白纸的周长分别为：1015.7，519.2，1255.9 。 手工软布尺测量1015.5-， 518.5-，1254.5+，误差小于 0.2 % 也可进行如下精度推理： 考虑到A4 大小标准为 297* 210， 即周长为 1014，误差小于0.2%。 右侧两个图形是由一张A4纸剪出，则可以中间图形的周长推导出右侧图形的周长： 中间白纸规则部分（即图形的左侧垂边，A4纸边）长度为139，则不规则部分为 519.2-139 = 380.2 最右侧图形的周长可以计算出：1014 -139 + 380.2 = 1255.2 误差也小于 0.2% 当每隔一像素采样取点时，结果计算为1016.9， 519.2，1251.7，误差小于0.4%，运行速度得到了提升。 2.2 识别背景并建立坐标系统2.2.1 对背景设别使用颜色聚类识别出背景色和前景色 2.2.2 对背景进行聚类目前实现了层次聚类和密度聚类，目前密度聚类实现的速度和性能都优于层次聚类 ，但内存使用还有待优化。 聚类后效果如下： 实际应该中，为了减少内存使用，背景可以读取上下左右指定宽度的像素点。 因为光照等原因，会有大量的错误象素点，使得聚类会产生多个聚族，选择像素点最多的聚族为背景图像。实际情况中背景聚类拥有的象素点数量远远多于错误聚类的象素点。 2.2.3 计算上下左右四角 将聚类后的背景（只剩下部分边框）按顺时针旋转45度，并获取最外侧像素 按上下左右四个点，将点划分为四个数组中，即可形成 上下左右 四条边的点集合 对每条边所有点进行一元线性回归，即拟合出 y = kx +b 的直线，操作如下： a. 对点进行排序，先x后y； b. 删除 首尾 1/4（可调）的像素点，首尾像素点识别错误的可能性很大，如该图中缺只角； c. 对剩下的点进行一元线性回归。 解四个二元线性方程组，计算出四条直线的交点。这四个交点就是新的上下左右四个点坐标 将计算后四个点逆时针旋转45度，即原始点的坐标 2.2.4 根据坐标点建立投影矩阵 用户需要输入背景的真实长度和宽度 目前没有考虑到透视情况。经过多次实验（从正上方，左上方，右上方等），当拍照角度不是特别倾斜的情况下，透视对最结果的影响极小。 实际应用中只使用了三个点，取出 左上，右上，左下 三点 ​ 2.3 获取待测物边界并连成多段线2.3.1 对待测物进行识别同背景识别一样，即对像素颜色进行判断。还需要判断像素点是否在背景区域内。 这里待测物为三张有规则或不规则白纸片，所以设置像素颜色为白色。 目前要求待测物的颜色是一样。 2.3.2 待测物体聚类同背景聚类一样，可以使用密度聚类或层次聚类。 考虑到图形的不规则性，聚类待测图片里，不能只取边缘像素。 聚类后的效果： 2.3.3 识别边界对每个聚类后图形进行Laplace滤波，识别图形的边界。 下图为对第三个图形识别出来的边界： 2.3.4 将图形边缘点生成多段线使用方位角的游走来实现。一个聚类中可以生成多条多段线，取像素点最多的进行返回。 实现在后面详述 2.4 计算多段线长度使用B样条插值： 使用滤波，过滤掉锯齿。测试高斯滤波，平均滤波对结果影响极小 对点进行采样，分别隔0，1，…，9个点进行采样 对采样后的点进行样条插值 两点间插入20（可调）个中间点 计算两点间欧式距离 累积所的的距离和，即结果 进所有结果进行加权平均即 多段线长度 3 用到的一些算法3.1 聚类3.1.1 Kmeans聚类用于区分前景色与背景色 过程： 去掉原始图像的边缘部分，随机采样出部分像素点 将像素点的颜色组成(R,G,B)的向量，所有的像素点组织成 3*N的矩阵 归一化颜色矩阵 计算颜色矩阵协方差矩阵，并计算PCA，并比例占90%以上的分量 将降维后的颜色矩阵使用Kmeans进行聚类，其中k=2 计算聚类内部像素点的平均距离，如果平均距离大，则该类为背景色，平均距离小，则为前景色 使用PCA的原因：颜色RGB值存在线性相关，如红色的RGB为(255, 0, 0)，白色为(255, 255,255)， 即绿色成分与蓝色成分线性相关 同时也有一个假设：背景比图形分布更散 3.1.2 GMM聚类用于区分前景色与背景色 过程： 采样像素颜色值及相关的降维处理同上 将降维后的颜色矩阵使用GMM进行聚类 ，其中k=2 循环所有的所有的像素点（降维后）判断该点占某一聚类的概率，并将该像素点划为概率值最大所在的类别 之后也是根据方差判断颜色 3.1.3 层次聚类用于识别出图形。 过程： 分解阶段 a. 按长方形划分区域 b. 如果当时区域内所有像素点都为前景色，同判断为一个 簇 ​ 如果当时区域内所有像素点都为非前景色，同舍弃该区域 ​ 如果当时区域内的像素点即有前景色又有非前景色，则按 左上，右上，左下，右下，四个区域继续划分区域 c. 重复a, b 过程 归并阶段 采用类似于最短路径算法实现 将所有的 簇 做为定义图的顶点，如果两个簇相邻，则距离为1， 否则距离为无穷 可以使用Dijkstra， floyd等算法记录两个簇之间的路径，只要路径不为无穷，则它们可以划为同一 簇 归并过程递归呀循环实现 3.1.4 密度聚类用于识别出图形。 定义所有点都为核心对象，相邻的像素为密度直达。 过程比较简单： 循环所有像素点，找出它密度直达的像素点 通过密度直达的像素点找到所有密度可达的像素点，并将其加入到集合中 循环1，2过程，返回聚类像素点的集合 3.2 一元线性回归3.3 多段线生成方法如下： 计算重心 任取一个像素计算该像素到重心的方位角 计算像素附近的其他像素点到重点的方位角 选择一个方向一致且方位角之差最小的像素做为后续点 循环2-4步，直到回到最初的像素点，则成环 或附近没有像素点，放弃该多段线 重复2-5步，直到处理像素点 取最长的多段线（应该取围成面积最大的多线段，但没有实现） 3.4 滤波高斯滤波 Laplace滤波 3.5 插值B样条插值 3.6 矩阵计算旋转 投影 4 示例代码Maven配置了是使用Java 1.7，一些1.8的新特性无法使用 以下代码在 GirthTest.java 文件中，可以指定一张新图片，运行该测试用用例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 运行时，下面四行赋值需要修改String imgPath = \"/Users/lichanghai/Mine/edgelen/images/naive.jpg\"; SupportColor backColor = SupportColor.Red;SupportColor foreColor = SupportColor.White;int clusterCount = 3;final BufferedImage img = ImageIO.read(new File(imgPath));final int width = img.getWidth();final int height = img.getHeight();final int[] pixels = new int[width * height];img.getRGB(0, 0, img.getWidth(), img.getHeight(), pixels, 0, width);ImagePixelHolder pixelHolder = new ImagePixelHolder(1, new PixelImage() &#123; @Override public int getWidth() &#123; return width; &#125; @Override public int getHeight() &#123; return height; &#125; @Override public int getColor(int x, int y) &#123; return pixels[y * width+x]; &#125;&#125;);EdgeCurve[] curves = LatticeUtils.getEdgeCurves(pixelHolder, 1052, 730, new KmeansColorSeparator(pixelHolder, 100000) , clusterCount, false);for (EdgeCurve curve : curves) &#123; GirthResult result = curve.getGirth(); System.out.println(\"default : \" + result.getRecommender()); for (double d : result.getOthers()) &#123; System.out.println(\"other girth : \" + d); &#125;&#125; 5 一些问题5.1 透视引起的精度问题 目前没有考虑透视影响。为了实现方面，该项目本质是只是在平面上进行处理。透视需要考虑到三维空间的问题，比较麻烦。 只要不是手机放得过于倾斜，透视带来的影响很小，几乎可以忽略。 5.2 不要旋转45度拍摄","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.lichanghai.com/tags/算法/"},{"name":"DBSCAN","slug":"DBSCAN","permalink":"http://www.lichanghai.com/tags/DBSCAN/"},{"name":"图形处理","slug":"图形处理","permalink":"http://www.lichanghai.com/tags/图形处理/"},{"name":"机器学习","slug":"机器学习","permalink":"http://www.lichanghai.com/tags/机器学习/"}],"keywords":[]},{"title":"Tarjan算法的并行化实现","slug":"parallel-tarjan","date":"2017-10-06T02:52:21.000Z","updated":"2018-12-02T09:10:42.532Z","comments":true,"path":"2017/10/06/parallel-tarjan/","link":"","permalink":"http://www.lichanghai.com/2017/10/06/parallel-tarjan/","excerpt":"","text":"Tarjan算法的并行化实现背景我们有时候有一些物品交换的需要，比如你手里有家乐福的购买券，但需要星巴克的购物券，这时候你就想如果 和其他人进行换一下，但实现中手里有星巴克优惠券而又需要家乐福购物券的人很难遇到，更多的场景 TA 可能需要家乐福的购物券但手里只有宜家的五折券等。 又或者在货币交易过程中，考虑到货币存在离岸在岸汇率差，同时在多种货币交易很难达到真正的汇率平衡，使得存在套利空间，举例来说我们先将人民币换成美元，再由美元换成日元，然后日元换成英镑，最后再换回人民币，这样最后换回的人民币数额可能会多于付出的数额（忽悠佣金，手续费等）。 上述系统本质是找到一个合适的交易链环。我们可以实现这样的交易系统，并使用Tarjan算法实现这些交易的环形撮合。 Tarjan算法比如存在交易: (A-&gt;B)、 (B-&gt;C)、(C-&gt;D)、(D-&gt;E)、(D-&gt;B)、(F-&gt;G)、(G-&gt;H)，其中(A-&gt;B)表示希望将A换成B，并定义（A-&gt;B) 表示 顶点A 与 顶点B 通过一条有向边相连，其中-&gt;前的顶点（节点）叫换出节点，-&gt;后的顶点（节点）叫换入节点。 上述定义中存在 A、B、C、D、E、F、G、H等节点，关系如下： 我们规定节点包括三种颜色，其中： 白色节点：节点未被访问过。 黑色节点：该节点已经确定无法成环，即无法成为任何一个环上的一个节点。 灰色节点：该节点已经被访问，但还无法确定是否能成环。 Tarjan的流程如下： 初始化所有的节点都涂成白色，表示本轮查找所有的节点都未访问过 从任何一个节点开始，假设我们从A节点开始，将A节点设置为灰色，并加入访问队列。 获取访问队列中的最后一个元素，并遍历能到达的节点 3.1 如果存在灰色节点，表示该节点已经被访问过，而经过一轮深度遍历后能回到该节点，表示我们已经找到了一个环，将访问队列中从该节点后的所有节点组成一个环并添加到环集合中，返回第1步重新执行。 3.2 如果只有白色节点，则随机选择一个白色节点，比如找到了B节点，则将B节点设置为灰色，并加入访问队列 3.3 如果只有黑色节点或没有任何节点，则说明这队列无法形成环，将该将该元素设置为黑色，并移出队列，返回第3步 如果队列为空，并存在白色节点，则从其他任意白色节点重新查找，重新执行步骤3。 如果所有的节点都为黑色，表示本次查找结束，并没有找到任何一个环。 实际应用中，我们可以使用Flink或Storm等实时消费Kafka中的消息，只有获取到一个kafka消息则开始一次查找，而且每次查找都应该从(A-&gt;B)中的B节点开始查找，因为其它节点在上次查找时已经被证明：如没有添加(A-&gt;B) 是无法形成环的。 注意，Tarjan算法是去尝试找到一个或多个能够形成交易的环，查找过程中不用关心这个节点是由谁创建，使用Tarjan算法的外部系统需要记录每个节点有多少用户希望换出，有多少用户希望换入，而且交易的边也要记录期望的交换量。在找到环后，则形成一笔或多笔交易，并适量调整这些值，并删除交换量为0的边。 这里并不打算深入讲解Tarjan算法，更多Tarjan相关资料请自行百度或Google。 Tarjan存在的问题tarjan算法存在的很大的一个问题就是无法并行化： 每次次查找前都要重置所有节点为白色，其它线程无法读取到正确的颜色状态。 找到环后再更新所影响到节点的权重及边的权重，则其它任务无法读取到正确的边或节点的权重。 更多。。。 这些都导致我们无法在多线程或多进程的情况下使用Tarjan进行环查找。而每次Kafka消息的到达都启动一次环形查找，在单线程环下也有大量压力。当然也可以定时启动一次或消息了多少条消息才启动一次Tarjan查找，但终究没有减少每次查找时的压力。 我们将Tarjan算法并行化的思想也很朴素，既然一次处理所有节点使得算法无法并行化，那为什么不将节点进行分组呢，我们每次查找环时只处理一个组里的相关节点及边。 我们期望组内的节点尽量相关，不同组间的节点尽量无关。那到底如何分级才能保证这一点呢？DBSCAN密码聚类算法为我们提供了一个解决该问题的思路。 DBSCANDBSCAN算法是机器学习中一个很朴素的聚类算法，根据图像的密度分布的，将图形中的点划分成不同的聚类。如下图中将所有的图划分为两个聚类，并分别设置为绿色和红色。 DBSCAN的一些概念（来源于：百度百科）： Ε邻域：给定对象半径为Ε内的区域称为该对象的Ε邻域； 核心对象：如果给定对象Ε邻域内的样本点数大于等于MinPts(最小点数量），则称该对象为核心对象； 直接密度可达：对于样本集合D，如果样本点q在p的Ε邻域内，并且p为核心对象，那么对象q从对象p直接密度可达。 密度可达：对于样本集合D，给定一串样本点p1,p2….pn，p= p1,q= pn,假如对象pi从pi-1直接密度可达，那么对象q从对象p密度可达。 密度相连：存在样本集合D中的一点o，如果对象o到对象p和对象q都是密度可达的，那么p和q密度相联。 如上图中： 圆圈即E邻域； E邻域内超过3个点就是核心点，如红色点； 单个绿点箭头为直接密度可达； 多个绿色箭头首尾相连，即密度可达； 平行化实现我们使用DBSCAN的思想进交易中的节点进行分组。 E邻域我们定义为无限大 邻域内的任何点都是核心点 如果存在一个交易(A-&gt;B)，则A与B节点密度可达 我们要做的就是从所有密度相连的节点，并使之形成多个聚类，如第一张图，则使用两个聚类： （A、B、C、D、E） （F、G、H） 我们只是借助于DBSCAN的思想，但实现将有区别于DBSCAN算法，流程如下： 初始化阶段做一次全量聚类，如上述分成两个聚类 到达一个消息 2.1 如果换入换出节点都在一个聚类中，如（A-&gt;B），则需要在聚类1 中使用tarjan算法查找环。 2.2 如果换入换出节点不在一个聚类中，如（A-G），则必不成环，这些需要将聚类1和2合并 随着时间的推移，越来越多的聚类会进行合并，但同时一个聚类中的也会有越来越多的边被删除，也就是说一个聚类中的所有节点可能并不是密度相连的，这些时需要对该聚类重新运行一次类DBSCAN算法，重新拆分该聚类。 这里解释一下3所说的情况，如一个聚类中存在三个节点（A,B,C) ，同时存在两条边 (A–3–&gt;B), ( B–1–&gt;C)，现在有一个交易消息(C–1–&gt;A)到来，经过Tarjan计算后删除环后的结果为，节点依然为3个(A, B,C)，但边只有一条了 (A–2–&gt;B) ，这时间就可以将 (A, B)生成一个聚类 ，（C）单独一个聚类。 仿DBSCAN算法的实现我们实现的类DBSCAN聚类算法使用深度遍历实现，流程如下： 使用Set保存聚类中的节点 从任意节点开始深度遍历所有能到达的节点，并将节点添加到Set中，节点本身也将指向该Set。 从其他没有遍历到的节点重新开始深度遍历，如果遍历的任何节点的set不为空，则将本轮遍历的节点添加到Set中 重复第3步，则到所有节点都已经被遍历过。 真实实现代码中参杂了大量的业务逻辑，上述流程做了极大的简化。整理后将再重新梳理流程，并贴上相关代码。","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.lichanghai.com/tags/算法/"},{"name":"DBSCAN","slug":"DBSCAN","permalink":"http://www.lichanghai.com/tags/DBSCAN/"},{"name":"Tarjan","slug":"Tarjan","permalink":"http://www.lichanghai.com/tags/Tarjan/"},{"name":"撮合算法","slug":"撮合算法","permalink":"http://www.lichanghai.com/tags/撮合算法/"}],"keywords":[]},{"title":"Hello World","slug":"hello-world","date":"2016-03-30T06:29:41.000Z","updated":"2018-11-23T17:39:41.489Z","comments":true,"path":"2016/03/30/hello-world/","link":"","permalink":"http://www.lichanghai.com/2016/03/30/hello-world/","excerpt":"","text":"Hi, 今天2016年3月30日，是个值得纪念的日子，我的博客诞生了，在我的农历生日前一天！","categories":[],"tags":[],"keywords":[]}]}